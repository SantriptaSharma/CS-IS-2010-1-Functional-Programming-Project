{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width  species\n",
       "17            5.1          3.5           1.4          0.3        0\n",
       "131           7.9          3.8           6.4          2.0        2\n",
       "18            5.7          3.8           1.7          0.3        0\n",
       "5             5.4          3.9           1.7          0.4        0\n",
       "93            5.0          2.3           3.3          1.0        1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualise 5 random rows from the iris dataset\n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "data['species'] = data['species'].astype('category').cat.codes\n",
    "data.iloc[np.random.permutation(data.shape[0])[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5,),\n",
       " (6,),\n",
       " (7,),\n",
       " (8,),\n",
       " (9,),\n",
       " (10,),\n",
       " (11,),\n",
       " (12,),\n",
       " (13,),\n",
       " (14,),\n",
       " (5, 5),\n",
       " (5, 8),\n",
       " (5, 11),\n",
       " (5, 14),\n",
       " (8, 5),\n",
       " (8, 8),\n",
       " (8, 11),\n",
       " (8, 14),\n",
       " (11, 5),\n",
       " (11, 8),\n",
       " (11, 11),\n",
       " (11, 14),\n",
       " (14, 5),\n",
       " (14, 8),\n",
       " (14, 11),\n",
       " (14, 14)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# possible hidden layer sizes to consider\n",
    "# single layer\n",
    "hidden_layer_sizes = [(i, ) for i in range(5, 15)]\n",
    "\n",
    "# two layers\n",
    "hidden_layer_sizes.extend([(i, j) for i in range(5, 15, 3) for j in range(5, 15, 3)])\n",
    "\n",
    "hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITER = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform 5-fold cross validation to find the best hidden layer size from the options\n",
    "res = GridSearchCV(MLPClassifier(max_iter = MAX_ITER), param_grid={'hidden_layer_sizes': hidden_layer_sizes}, cv=5).fit(data.iloc[:, 0:4], data.iloc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,0:4], data.iloc[:,4], test_size=0.25, random_state=0)\n",
    "pd.concat([X_test, y_test], axis = 1).to_csv(\"iris_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'hidden_layer_sizes': (7,)},\n",
       " 0.9866666666666667,\n",
       " 0.9736842105263158,\n",
       " array([0, 1, 2], dtype=int8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.best_params_, res.best_score_, res.score(X_test, y_test), res.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7,),\n",
       " (11, 8),\n",
       " (10,),\n",
       " (5,),\n",
       " (11, 14),\n",
       " (8, 5),\n",
       " (5, 11, 8),\n",
       " (9, 14, 7, 26, 27, 12, 14, 6, 14, 17, 16, 27)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get best 5 models\n",
    "best = res.cv_results_['rank_test_score'].argsort()\n",
    "indices = np.append(best[:5], best[-1])\n",
    "params = [d['hidden_layer_sizes'] for d in np.array(res.cv_results_['params'])[indices]]\n",
    "params.extend([(5, 11, 8), tuple([np.random.randint(5, 30) for i in range(12)])])\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with hidden layer sizes (7,)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (11, 8)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (10,)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (5,)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (11, 14)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (8, 5)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (5, 11, 8)\n",
      "accuracy: 0.9736842105263158\n",
      "\n",
      "training model with hidden layer sizes (9, 14, 7, 26, 27, 12, 14, 6, 14, 17, 16, 27)\n",
      "accuracy: 0.9736842105263158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from struct import pack\n",
    "\n",
    "for p in params:\n",
    "\tprint(f\"training model with hidden layer sizes {p}\")\n",
    "\tmodel = MLPClassifier(hidden_layer_sizes = p, max_iter = MAX_ITER).fit(X_train, y_train)\n",
    "\tprint(f\"accuracy: {model.score(X_test, y_test)}\")\n",
    "\n",
    "\tfname = f'trained_iris_model_{\"_\".join([str(s) for s in p])}'\n",
    "\twith open(f\"models/{fname}.pkl\", \"wb\") as f:\n",
    "\t\tpickle.dump(model, f)\n",
    "\t\n",
    "\tlayers = len(model.coefs_)\n",
    "\t# number of cols of weights matrix, this is pre transpose\n",
    "\tinput_neurons = model.coefs_[0].shape[0]\n",
    "\n",
    "\twith open(f\"weights/{fname}.mdl\", 'wb') as f:\n",
    "\t\tf.write(pack('I', layers))\n",
    "\t\tf.write(pack('I', input_neurons))\n",
    "\t\tfor i in range(layers):\n",
    "\t\t\tweights = model.coefs_[i].transpose()\n",
    "\t\t\tf.write(pack('I', weights.shape[0]))\n",
    "\t\t\tweights = list(weights.flatten())\n",
    "\t\t\tf.write(pack('d' * len(weights), *weights))\n",
    "\t\t\tbiases = list(model.intercepts_[i])\n",
    "\t\t\tf.write(pack('d' * len(biases), *biases))\n",
    "\t\n",
    "\tprint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
